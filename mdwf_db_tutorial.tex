\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{fancyvrb}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\geometry{margin=1in}

% Define colors for syntax highlighting
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

% Configure listings for terminal output
\lstdefinestyle{terminal}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    literate={_}{\_}1
}

\lstset{style=terminal}

% Custom command for code with underscores
\newcommand{\code}[1]{\texttt{\detokenize{#1}}}

\title{MDWF Database Management Tool\\Complete Tutorial \& Command Reference}
\author{LQCD Workflow Management}
\date{\today}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Installation \& Setup}

\subsection{Installing the CLI Tool}

Install the MDWF package to use the \code{mdwf_db} command directly:

\begin{lstlisting}[language=bash, caption=Installing MDWF CLI]
$ pip install -e /path/to/mdwf_db
Successfully installed MDWFutils-0.1

# Now you can use the mdwf_db command directly
$ mdwf_db --help
\end{lstlisting}

\subsection{Perlmutter Environment Setup}

On Perlmutter, you can load the MDWF environment using:

\begin{lstlisting}[language=bash]
module load conda
conda activate /global/cfs/cdirs/m2986/cosmon/mdwf/scripts/cosmon_mdwf
\end{lstlisting}

This will make the \code{mdwf_db} command available in your shell.

\section{Complete Command Reference}

\subsection{Database Management Commands}

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Command} & \textbf{Alias} & \textbf{Purpose} & \textbf{Key Options} \\
\hline
\texttt{init-db} & \texttt{init} & Initialize database and directory structure & \texttt{--base-dir}, \texttt{--db-file} \\
\hline
\texttt{add-ensemble} & \texttt{add} & Add ensemble to database & \texttt{-p/--params}, \texttt{-s/--status}, \texttt{-d/--directory} \\
\hline
\texttt{query} & \texttt{q} & List and inspect ensembles & \texttt{-e/--ensemble}, \texttt{--operations}, \texttt{--params} \\
\hline
\texttt{promote-ensemble} & \texttt{promote} & Move from TUNING to PRODUCTION & \texttt{-e/--ensemble}, \texttt{--force} \\
\hline
\texttt{remove-ensemble} & \texttt{remove} & Remove ensemble completely & \texttt{-e/--ensemble}, \texttt{--force} \\
\hline
\texttt{clear-history} & \texttt{clear} & Clear operation history & \texttt{-e/--ensemble}, \texttt{--force} \\
\hline
\end{tabular}
\caption{Database Management Commands}
\end{table}

\subsection{Script Generation Commands}

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Command} & \textbf{Alias} & \textbf{Purpose} & \textbf{Key Options} \\
\hline
\texttt{hmc-script} & \texttt{hmc} & Generate HMC XML and SLURM script & \texttt{-e}, \texttt{-a}, \texttt{-m}, \texttt{-x}, \texttt{-j}, \texttt{--use-default-params} \\
\hline
\texttt{hmc-xml} & \texttt{hmc-x} & Generate standalone HMC XML & \texttt{-e}, \texttt{-m}, \texttt{-x}, \texttt{-o} \\
\hline
\texttt{smear-script} & \texttt{smear} & Generate GLU smearing script & \texttt{-e}, \texttt{-j}, \texttt{-g}, \texttt{--use-default-params} \\
\hline
\texttt{wflow-script} & \texttt{wflow} & Generate gradient flow script & \texttt{-e}, \texttt{-j}, \texttt{-g}, \texttt{--use-default-params} \\
\hline
\texttt{meson2pt-script} & \texttt{meson} & Generate WIT meson script & \texttt{-e}, \texttt{-j}, \texttt{-w}, \texttt{--use-default-params} \\
\hline
\texttt{mres-script} & \texttt{mres} & Generate WIT MRES script & \texttt{-e}, \texttt{-j}, \texttt{-g}, \texttt{--use-default-params} \\
\hline
\texttt{glu-input} & \texttt{glu} & Generate GLU input file & \texttt{-e}, \texttt{-o}, \texttt{-g}, \texttt{-t} \\
\hline
\texttt{wit-input} & \texttt{wit} & Generate WIT input file & \texttt{-e}, \texttt{-o}, \texttt{-w} \\
\hline
\end{tabular}
\caption{Script Generation Commands}
\end{table}


\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Command} & \textbf{Alias} & \textbf{Purpose} & \textbf{Key Options} \\
\hline
\texttt{default\_params} & \texttt{defaults} & Manage default parameter files & \texttt{generate}, \texttt{show}, \texttt{edit}, \texttt{validate} \\
\hline
\end{tabular}
\caption{Parameter Management Commands}
\end{table}


\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Command} & \textbf{Alias} & \textbf{Purpose} & \textbf{Key Options} \\
\hline
\texttt{update} & \texttt{u} & Record/update operation status & \texttt{-e}, \texttt{-o}, \texttt{-s}, \texttt{-p}, \texttt{-u} \\
\hline
\end{tabular}
\caption{Operation Tracking Commands}
\end{table}

\subsection{Common Options Across Commands}

The following options are used consistently across most MDWF commands:

\begin{itemize}
\item \texttt{-e, --ensemble}: \textbf{Ensemble identifier} - Can be an ensemble ID (integer), directory path, or "." for current directory. This is the most commonly used option.

\item \texttt{-j, --job-params}: \textbf{SLURM/Job parameters} - Space-separated key=value pairs for job submission parameters like \texttt{time\_limit}, \texttt{nodes}, \texttt{mail\_user}, etc.

\item \texttt{-x, --xml-params}: \textbf{HMC XML parameters} - Used in HMC commands for physics parameters like \texttt{Trajectories}, \texttt{MDsteps}, \texttt{trajL}, etc.

\item \texttt{-w, --wit-params}: \textbf{WIT input parameters} - Used in WIT-based commands for measurement parameters like \texttt{Configurations.first}, \texttt{Propagator 0.Source}, etc.

\item \texttt{-g, --glu-params}: \textbf{GLU input parameters} - Used in GLU-based commands for smearing and utility parameters like \texttt{SMITERS}, \texttt{ALPHA1}, etc.

\item \texttt{--db-file}: Database file path (auto-discovered by default)
\item \texttt{--use-default-params}: Load from ensemble default parameter file
\item \texttt{--save-default-params}: Save current parameters to default file
\item \texttt{--params-variant}: Use specific parameter variant
\item \texttt{--save-params-as}: Save under custom variant name
\end{itemize}







\subsection{init-db: Initialize Database}

\textbf{Purpose:} Create a new MDWF database and directory structure.

This command initializes a SQLite database with the required schema and creates the TUNING/ and ENSEMBLES/ directory structure.

\textbf{Options:}
\begin{itemize}
\item \texttt{--db-file DB\_FILE}: Path to SQLite database (optional, auto-discovered by default)
\item \texttt{--base-dir BASE\_DIR}: Root directory for TUNING/ and ENSEMBLES/ (default: current directory)
\end{itemize}

\textbf{Examples:}

\begin{lstlisting}[language=bash]
# Initialize database in current directory
$ mkdir -p /scratch/lattice/my_project && cd /scratch/lattice/my_project
$ mdwf_db init-db
Ensured directory: /scratch/lattice/my_project
Ensured directory: /scratch/lattice/my_project/TUNING  
Ensured directory: /scratch/lattice/my_project/ENSEMBLES
init_database returned: True

$ ls -la
-rw-r--r-- 1 user group 40960 mdwf_ensembles.db
drwxr-xr-x 2 user group    64 ENSEMBLES/
drwxr-xr-x 2 user group    64 TUNING/

# Initialize with custom base directory
$ mdwf_db init-db --base-dir /tmp/mdwf_expanded_test
Ensured directory: /private/tmp/mdwf_expanded_test
Ensured directory: /private/tmp/mdwf_expanded_test/TUNING
Ensured directory: /private/tmp/mdwf_expanded_test/ENSEMBLES
init_database returned: True
\end{lstlisting}

\subsection{add-ensemble: Add New Ensemble}

\textbf{Purpose:} Add a new ensemble to the database with physics parameters.

Creates the ensemble directory structure and adds the record to the database with all physics parameters.

\textbf{Options:}
\begin{itemize}
\item \texttt{-p, --params PARAMS}: \textbf{Required.} Space-separated key=val pairs for physics parameters
\item \texttt{-s, --status \{TUNING,PRODUCTION\}}: \textbf{Required.} Ensemble status
\item \texttt{-d, --directory DIRECTORY}: Explicit directory path (overrides auto-generated path)
\item \texttt{-b, --base-dir BASE\_DIR}: Root directory for TUNING/ENSEMBLES (default: current)
\item \texttt{--description DESCRIPTION}: Optional description text
\end{itemize}

\textbf{Required Physics Parameters:}
beta, b, Ls, mc, ms, ml, L, T

\textbf{Directory Structure Created:}

\texttt{<STATUS>/b<beta>/b<b>Ls<Ls>/mc<mc>/}\\
\texttt{ms<ms>/ml<ml>/L<L>/T<T>/}

Each ensemble directory contains:
\begin{itemize}
\item \texttt{cnfg/}: Gauge configuration files
\item \texttt{slurm/}: Generated SLURM scripts  
\item \texttt{jlog/}: Job logs and output
\item \texttt{log\_hmc/}: HMC-specific logs
\end{itemize}

\textbf{Examples:}
\begin{lstlisting}[language=bash]
# Add TUNING ensemble with standard parameters
$ mdwf_db add-ensemble \
    -p "beta=6.0 b=1.8 Ls=24 mc=0.8555 ms=0.0725 ml=0.0195 L=32 T=64" \
    -s TUNING \
    --description "First test ensemble - 32^3x64"
Ensemble added: ID=1

# Add second ensemble with different physics parameters
$ mdwf_db add-ensemble \
    -p "beta=5.8 b=2.0 Ls=16 mc=0.9 ms=0.08 ml=0.02 L=24 T=48" \
    -s TUNING \
    --description "Second test ensemble - 24^3x48 with different parameters"
Ensemble added: ID=2

# Add ensemble directly in PRODUCTION status
$ mdwf_db add-ensemble \
    -p "beta=6.2 b=1.5 Ls=32 mc=0.8 ms=0.06 ml=0.015 L=48 T=96" \
    -s PRODUCTION \
    --description "Large production ensemble - 48^3x96"
Ensemble added: ID=3
Marked PRODUCTION in DB: OK

$ find TUNING -name "*" -type d | head -5
TUNING
TUNING/b6.0
TUNING/b6.0/b1.8Ls24
TUNING/b6.0/b1.8Ls24/mc0.8555
TUNING/b6.0/b1.8Ls24/mc0.8555/ms0.0725
\end{lstlisting}

\subsection{query: List and Inspect Ensembles}

\textbf{Purpose:} Query ensemble information from the database.

The query command has two distinct modes: list mode (shows all ensembles) and detail mode (shows information for one specific ensemble).

\textbf{Options:}
\begin{itemize}
\item \texttt{-e, --ensemble ENSEMBLE}: Show details for specific ensemble (ID, path, or ".")
\item \texttt{--detailed}: In list mode, show descriptions and operation counts
\item \texttt{--sort-by-id}: In list mode, sort ensembles by EID instead of by parameters
\item \texttt{--dir}: Show only the directory path (only works with \texttt{--ensemble})
\end{itemize}

\textbf{Two Modes:}

\textbf{1. List Mode (no ensemble specified):}
Shows a spreadsheet-like table of all ensembles with columns:
\texttt{EID > beta > b > Ls > mc > ms > ml > L > T > LAST\_OP > LAST\_USER}

By default, ensembles are sorted numerically/alphabetically by parameters. Use \texttt{--sort-by-id} to sort by EID.

\textbf{2. Detail Mode (with ensemble specified):}
Shows complete information for one ensemble including:
\begin{itemize}
\item All physics parameters (beta, masses, lattice dimensions)
\item Full operation history with timestamps and parameters
\item Job status and configuration ranges
\end{itemize}

\textbf{Flexible Ensemble Identification:}
The \texttt{--ensemble} parameter accepts multiple formats:
\begin{itemize}
\item Ensemble ID: \texttt{-e 1}
\item Relative path: \texttt{-e ./TUNING/b6.0/b1.8Ls24/mc0.85/ms0.07/ml0.02/L32/T64}
\item Absolute path: \texttt{-e /full/path/to/ensemble}
\item Current directory: \texttt{-e .} (when run from within ensemble directory)
\end{itemize}

\textbf{Examples:}
\begin{lstlisting}[language=bash]
# List all ensembles in spreadsheet format (sorted by parameters)
$ mdwf_db query
EID > beta > b > Ls > mc > ms > ml > L > T > LAST_OP > LAST_USER
1 > 6.0 > 1.8 > 24 > 0.8555 > 0.0725 > 0.0195 > 32 > 64 > HMC_TUNE > wyatt
2 > 5.8 > 2.0 > 16 > 0.9 > 0.08 > 0.02 > 24 > 48 > GLU_SMEAR > alice
3 > 6.2 > 1.5 > 32 > 0.8 > 0.06 > 0.015 > 48 > 96 > WIT_MESON2PT > bob

# List all ensembles sorted by EID
$ mdwf_db query --sort-by-id
EID > beta > b > Ls > mc > ms > ml > L > T > LAST_OP > LAST_USER
1 > 6.0 > 1.8 > 24 > 0.8555 > 0.0725 > 0.0195 > 32 > 64 > HMC_TUNE > wyatt
2 > 5.8 > 2.0 > 16 > 0.9 > 0.08 > 0.02 > 24 > 48 > GLU_SMEAR > alice
3 > 6.2 > 1.5 > 32 > 0.8 > 0.06 > 0.015 > 48 > 96 > WIT_MESON2PT > bob

# List with descriptions and operation counts
$ mdwf_db query --detailed
EID > beta > b > Ls > mc > ms > ml > L > T > LAST_OP > LAST_USER > Description > Operations
1 > 6.0 > 1.8 > 24 > 0.8555 > 0.0725 > 0.0195 > 32 > 64 > HMC_TUNE > wyatt > First test ensemble - 32^3x64 > 3
2 > 5.8 > 2.0 > 16 > 0.9 > 0.08 > 0.02 > 24 > 48 > GLU_SMEAR > alice > Second test ensemble - 24^3x48 > 1
3 > 6.2 > 1.5 > 32 > 0.8 > 0.06 > 0.015 > 48 > 96 > WIT_MESON2PT > bob > Large production ensemble - 48^3x96 > 2

# Show detailed information for specific ensemble by ID
$ mdwf_db query -e 2
ID          = 2
Directory   = /path/to/ENSEMBLES/b5.8/b2.0Ls16/mc0.9/ms0.08/ml0.02/L24/T48
Status      = PRODUCTION
Created     = 2025-08-06T12:40:49.869456
Description = Second test ensemble - 24^3x48 with different parameters
Parameters:
    L = 24
    Ls = 16
    T = 48
    b = 2.0
    beta = 5.8
    mc = 0.9
    ml = 0.02
    ms = 0.08

=== Operation history ===
Op 1: GLU_SMEAR [COMPLETED]
  Created: 2025-08-06T12:41:44.054003 (by alice)
  Updated: 2025-08-06T12:42:15.123456
    config_start = 10
    config_end = 30
    exit_code = 0
    runtime = 1800

# Query using relative path instead of ID
$ mdwf_db query -e ./TUNING/b6.0/b1.8Ls24/mc0.8555/ms0.0725/ml0.0195/L32/T64
[Shows same detailed information as above]

# Query from within ensemble directory using "."
$ cd TUNING/b6.0/b1.8Ls24/mc0.8555/ms0.0725/ml0.0195/L32/T64
$ mdwf_db query -e .
[Shows same detailed information as above]

# Show only the directory path for an ensemble
$ mdwf_db query -e 1 --dir
/path/to/TUNING/b6.0/b1.8Ls24/mc0.8555/ms0.0725/ml0.0195/L32/T64
\end{lstlisting}

\subsection{promote-ensemble: Move to Production}

\textbf{Purpose:} Move ensemble from TUNING to PRODUCTION status and directory.

Physically moves the directory and updates the database record. Records a PROMOTE\_ENSEMBLE operation in the history.

\textbf{Options:}
\begin{itemize}
\item \texttt{-e, --ensemble ENSEMBLE}: \textbf{Required.} Ensemble to promote (ID, path, or ".")
\item \texttt{--base-dir BASE\_DIR}: Root directory containing TUNING/ and ENSEMBLES/
\item \texttt{--force}: Skip confirmation prompt
\end{itemize}

\textbf{Requirements:}
\begin{itemize}
\item Ensemble must have TUNING status
\item Target ENSEMBLES/ directory must not exist
\item Source must be under TUNING/
\end{itemize}

\textbf{Examples:}
\begin{lstlisting}[language=bash]
# Promote with confirmation prompt
$ mdwf_db promote-ensemble -e 1
Promote ensemble 1:
  from /scratch/lattice/TUNING/b6.0/b1.8Ls24/mc0.8555/ms0.0725/ml0.0195/L32/T64
    to /scratch/lattice/ENSEMBLES/b6.0/b1.8Ls24/mc0.8555/ms0.0725/ml0.0195/L32/T64
Proceed? (y/N) y
Created operation 2: Created
Promotion OK

# Promote with --force flag (skips confirmation)
$ mdwf_db promote-ensemble -e 2 --force
Promote ensemble 2:
  from /private/tmp/mdwf_expanded_test/TUNING/b5.8/b2.0Ls16/mc0.9/ms0.08/ml0.02/L24/T48
    to /private/tmp/mdwf_expanded_test/ENSEMBLES/b5.8/b2.0Ls16/mc0.9/ms0.08/ml0.02/L24/T48
Created operation 4: Created
Promotion OK

# Verify the move
$ ls ENSEMBLES/b6.0/b1.8Ls24/mc0.8555/ms0.0725/ml0.0195/L32/T64/
cnfg/  jlog/  log_hmc/  slurm/
\end{lstlisting}

\subsection{hmc-script: Generate HMC Scripts}

\textbf{Purpose:} Generate HMC XML parameters and SLURM batch script for gauge generation.

Creates both XML parameter files and complete SLURM scripts for GPU HMC execution.

\textbf{Options:}
\begin{itemize}
\item \texttt{-e, --ensemble-id ENSEMBLE\_ID}: \textbf{Required.} Ensemble ID
\item \texttt{-a, --account ACCOUNT}: \textbf{Required.} SLURM account name
\item \texttt{-m, --mode \{tepid,continue,reseed\}}: \textbf{Required.} HMC run mode
\item \texttt{-x, --xml-params XML\_PARAMS}: Space-separated XML parameters
\item \texttt{-j, --job-params JOB\_PARAMS}: Space-separated SLURM job parameters  
\item \texttt{-o, --output-file OUTPUT\_FILE}: Custom output script path
\item \texttt{--use-default-params}: Load from ensemble default parameter file
\item \texttt{--params-variant VARIANT}: Use specific parameter variant  
\item \texttt{--save-default-params}: Save current parameters to default file
\item \texttt{--save-params-as VARIANT}: Save under custom variant name
\end{itemize}

\textbf{HMC Modes:}
\begin{itemize}
\item \textbf{tepid}: Initial thermalization run (TepidStart)
\item \textbf{continue}: Continue from existing checkpoint (CheckpointStart)  
\item \textbf{reseed}: Start new run with different seed (CheckpointStartReseed)
\end{itemize}

\textbf{Required Job Parameters:}
\texttt{cfg\_max}: Maximum configuration number to generate

\textbf{Common XML Parameters:}
StartTrajectory, Trajectories, MetropolisTest, MDsteps, trajL, Seed

\textbf{Examples:}
\begin{lstlisting}[language=bash]
# Basic tepid HMC script with minimal parameters
$ printf "/usr/bin/hmc_exec\n/usr/bin/core_bind.sh\n" | \
  mdwf_db hmc-script -e 1 -a m2986 -m tepid -j "cfg_max=50 time_limit=6:00:00"
Generated HMC script: /private/tmp/.../TUNING/.../slurm/hmc_1_tepid.sbatch

# Continue mode with custom XML and job parameters  
$ printf "/usr/bin/hmc_exec\n/usr/bin/core_bind.sh\n" | \
  mdwf_db hmc-script -e 2 -a nersc -m continue \
    -j "cfg_max=200 time_limit=12:00:00 nodes=2" \
    -x "StartTrajectory=50 Trajectories=100 MDsteps=4"
Generated HMC script: /private/tmp/.../TUNING/.../slurm/hmc_2_continue.sbatch

# Use stored default parameters from file
$ printf "/usr/bin/hmc_exec\n/usr/bin/core_bind.sh\n" | \
  mdwf_db hmc-script -e 1 -a m2986 -m continue --use-default-params -j "nodes=2"
Loaded HMC continue default parameters from .../mdwf_default_params.yaml
Generated HMC script: /private/tmp/.../TUNING/.../slurm/hmc_1_continue.sbatch

# Save parameters for future reuse
$ printf "/usr/bin/hmc_exec\n/usr/bin/core_bind.sh\n" | \
  mdwf_db hmc-script -e 1 -a m2986 -m tepid \
    -j "cfg_max=25 time_limit=3:00:00" \
    -x "MDsteps=6 trajL=0.5" --save-default-params
Generated HMC script: /private/tmp/.../slurm/hmc_1_tepid.sbatch
Saved parameters to default params: hmc.tepid
\end{lstlisting}

\textbf{Complete Generated SLURM Scripts:}

Here are the complete SLURM batch scripts generated by different option combinations, showing all the logic, environment setup, database integration, and execution flow:

\textbf{Example 1: Complete Tepid Mode Script (24$^3$\texttimes 48 lattice)}
\begin{lstlisting}[language=bash]
# Generated by: mdwf_db hmc-script -e 1 -a physics123 -m tepid \
#   -j "time_limit=1:00:00 nodes=2 ntasks_per_node=4 cfg_max=100"

#!/bin/bash
#SBATCH -A physics123
#SBATCH -C gpu
#SBATCH -q regular
#SBATCH -t 1:00:00
#SBATCH --cpus-per-task=32
#SBATCH -N 2
#SBATCH --ntasks-per-node=4
#SBATCH --gres=gpu:1
#SBATCH --gpu-bind=none
#SBATCH --mail-type=BEGIN,END
#SBATCH --mail-user=wyatt
#SBATCH --signal=B:TERM@60

batch="$0"
DB="/path/to/mdwf_ensembles.db"
EID=1
mode="tepid"
ens="b2.10_b1.0Ls32_mc0.04_ms0.04_ml0.005_L24_T48"
ens_rel="24^3x48 test ensemble"
VOL="24.24.24.48"
EXEC="/opt/exec_file"
BIND="/opt/exec_file"
n_trajec=100
cfg_max=100
mpi="2.1.1.2"

cd /path/to/24^3x48\ test\ ensemble

echo "ens = $ens"
echo "ens_dir = /path/to/24^3x48 test ensemble"
echo "EXEC = $EXEC"
echo "BIND = $BIND"
echo "n_trajec = $n_trajec"
echo "cfg_max = $cfg_max"

mkdir -p cnfg
mkdir -p log_hmc

start=`ls -v cnfg/| grep lat | tail -1 | sed 's/[^0-9]*//g'`
if [[ -z $start ]]; then
    echo "no configs - start is empty - doing TepidStart"
    start=0
fi

# check if start <= cfg_max
if [[ $start -ge $cfg_max ]]; then
    echo "your latest config is greater than the target:"
    echo "  $start >= $cfg_max"
    exit
fi

echo "cfg_current = $start"

# Update database to show running job
out=$(
  mdwf_db update \
    --db-file="$DB" \
    --ensemble-id=$EID \
    --operation-type="$mode" \
    --status=RUNNING \
    --params="config_start=$start config_end=$(( start + n_trajec )) config_increment=$n_trajec slurm_job=$SLURM_JOB_ID exec_path=$EXEC bind_script=$BIND"
)
echo "$out"
op_id=${out#*operation }
op_id=${op_id%%:*}
export op_id

# Generate HMC parameters XML
mdwf_db hmc-xml -e $EID -m $mode --params "StartTrajectory=$start Trajectories=$n_trajec"

cp HMCparameters.xml cnfg/
cd cnfg

export CRAY_ACCEL_TARGET=nvidia80
export MPICH_OFI_NIC_POLICY=GPU
export SLURM_CPU_BIND="cores"
export MPICH_GPU_SUPPORT_ENABLED=1
export MPICH_RDMA_ENABLED_CUDA=1
export MPICH_GPU_IPC_ENABLED=1
export MPICH_GPU_EAGER_REGISTER_HOST_MEM=0
export MPICH_GPU_NO_ASYNC_MEMCPY=0
export OMP_NUM_THREADS=8

echo "Nthreads $OMP_NUM_THREADS"

echo "START `date`"
srun $BIND $EXEC --mpi $mpi --grid $VOL --accelerator-threads 32 --dslash-unroll --shm 2048 --comms-overlap -shm-mpi 0 > ../log_hmc/log_b2.10_b1.0Ls32_mc0.04_ms0.04_ml0.005_L24_T48.$start
EXIT_CODE=$?
echo "STOP `date`"

# Update database with job status
STATUS=COMPLETED
[[ $EXIT_CODE -ne 0 ]] && STATUS=FAILED

mdwf_db update \
  --db-file="$DB" \
  --ensemble-id=$EID \
  --operation-id=$op_id \
  --operation-type="$mode" \
  --status=$STATUS \
  --params="exit_code=$EXIT_CODE runtime=$SECONDS slurm_job=$SLURM_JOB_ID host=$(hostname)"

echo "DB updated: operation $op_id to $STATUS (exit=$EXIT_CODE) [SLURM_JOB_ID=$SLURM_JOB_ID]"

# Check if we should resubmit
if [[ $EXIT_CODE -eq 0 && "true" == "true" && $mode != "reseed" ]]; then
    next_start=$((start + n_trajec))
    if [[ $next_start -lt $cfg_max ]]; then
        echo "Resubmitting with start=$next_start in continue mode"
        # Generate new XML for continue mode
        mdwf_db hmc-xml -e $EID -m continue --params "StartTrajectory=$next_start Trajectories=$n_trajec"
        # Resubmit the job
        sbatch --dependency=afterok:$SLURM_JOBID $batch
    else
        echo "Reached target config_max=$cfg_max"
    fi
fi

exit $EXIT_CODE
\end{lstlisting}

\textbf{Example 2: Complete Continue Mode Script (32$^3$\texttimes 64 lattice)}
\begin{lstlisting}[language=bash]
# Generated by: mdwf_db hmc-script -e 2 -a physics456 -m continue \
#   -j "time_limit=4:00:00 nodes=4 ntasks_per_node=8 cfg_max=500"

#!/bin/bash
#SBATCH -A physics456
#SBATCH -C gpu
#SBATCH -q regular
#SBATCH -t 4:00:00
#SBATCH --cpus-per-task=32
#SBATCH -N 4
#SBATCH --ntasks-per-node=8
#SBATCH --gres=gpu:1
#SBATCH --gpu-bind=none
#SBATCH --mail-type=BEGIN,END
#SBATCH --mail-user=wyatt
#SBATCH --signal=B:TERM@60

batch="$0"
DB="/path/to/mdwf_ensembles.db"
EID=2
mode="continue"
ens="b2.13_b1.0Ls16_mc0.04_ms0.04_ml0.005_L32_T64"
ens_rel="32^3x64 production ensemble"
VOL="32.32.32.64"
EXEC="/usr/exec_file_2"
BIND="/usr/local/bin/bind.sh"
n_trajec=500
cfg_max=500
mpi="2.1.1.2"

cd /path/to/32^3x64\ production\ ensemble

echo "ens = $ens"
echo "ens_dir = /path/to/32^3x64 production ensemble"
echo "EXEC = $EXEC"
echo "BIND = $BIND"
echo "n_trajec = $n_trajec"
echo "cfg_max = $cfg_max"

mkdir -p cnfg
mkdir -p log_hmc

start=`ls -v cnfg/| grep lat | tail -1 | sed 's/[^0-9]*//g'`
if [[ -z $start ]]; then
    echo "no configs - start is empty - doing TepidStart"
    start=0
fi

# check if start <= cfg_max
if [[ $start -ge $cfg_max ]]; then
    echo "your latest config is greater than the target:"
    echo "  $start >= $cfg_max"
    exit
fi

echo "cfg_current = $start"

# Update database to show running job
out=$(
  mdwf_db update \
    --db-file="$DB" \
    --ensemble-id=$EID \
    --operation-type="$mode" \
    --status=RUNNING \
    --params="config_start=$start config_end=$(( start + n_trajec )) config_increment=$n_trajec slurm_job=$SLURM_JOB_ID exec_path=$EXEC bind_script=$BIND"
)
echo "$out"
op_id=${out#*operation }
op_id=${op_id%%:*}
export op_id

# Generate HMC parameters XML
mdwf_db hmc-xml -e $EID -m $mode --params "StartTrajectory=$start Trajectories=$n_trajec"

cp HMCparameters.xml cnfg/
cd cnfg

export CRAY_ACCEL_TARGET=nvidia80
export MPICH_OFI_NIC_POLICY=GPU
export SLURM_CPU_BIND="cores"
export MPICH_GPU_SUPPORT_ENABLED=1
export MPICH_RDMA_ENABLED_CUDA=1
export MPICH_GPU_IPC_ENABLED=1
export MPICH_GPU_EAGER_REGISTER_HOST_MEM=0
export MPICH_GPU_NO_ASYNC_MEMCPY=0
export OMP_NUM_THREADS=8

echo "Nthreads $OMP_NUM_THREADS"

echo "START `date`"
srun $BIND $EXEC --mpi $mpi --grid $VOL --accelerator-threads 32 --dslash-unroll --shm 2048 --comms-overlap -shm-mpi 0 > ../log_hmc/log_b2.13_b1.0Ls16_mc0.04_ms0.04_ml0.005_L32_T64.$start
EXIT_CODE=$?
echo "STOP `date`"

# Update database with job status
STATUS=COMPLETED
[[ $EXIT_CODE -ne 0 ]] && STATUS=FAILED

mdwf_db update \
  --db-file="$DB" \
  --ensemble-id=$EID \
  --operation-id=$op_id \
  --operation-type="$mode" \
  --status=$STATUS \
  --params="exit_code=$EXIT_CODE runtime=$SECONDS slurm_job=$SLURM_JOB_ID host=$(hostname)"

echo "DB updated: operation $op_id to $STATUS (exit=$EXIT_CODE) [SLURM_JOB_ID=$SLURM_JOB_ID]"

# Check if we should resubmit
if [[ $EXIT_CODE -eq 0 && "true" == "true" && $mode != "reseed" ]]; then
    next_start=$((start + n_trajec))
    if [[ $next_start -lt $cfg_max ]]; then
        echo "Resubmitting with start=$next_start in continue mode"
        # Generate new XML for continue mode
        mdwf_db hmc-xml -e $EID -m continue --params "StartTrajectory=$next_start Trajectories=$n_trajec"
        # Resubmit the job
        sbatch --dependency=afterok:$SLURM_JOBID $batch
    else
        echo "Reached target config_max=$cfg_max"
    fi
fi

exit $EXIT_CODE
\end{lstlisting}

\textbf{Key Differences Between Tepid and Continue Scripts:}

\begin{itemize}
\item \textbf{SLURM Resources:} Continue mode uses more nodes (4 vs 2) and tasks (8 vs 4) for production runs
\item \textbf{Grid Size:} Different lattice volumes reflected in VOL variable (32$^3$\texttimes 64 vs 24$^3$\texttimes 48)
\item \textbf{Configuration Targets:} Higher cfg\_max for production (500 vs 100)
\item \textbf{Executable Paths:} Different EXEC and BIND paths based on user input
\item \textbf{Environment:} Both scripts set identical GPU/MPI environment variables for HPC execution
\item \textbf{Database Integration:} Both track operations with status updates and parameter logging
\item \textbf{Auto-resubmission:} Both include logic to chain jobs until cfg\_max is reached
\item \textbf{Directory Structure:} Ensemble-specific paths derived from physics parameters
\end{itemize}

\subsection{hmc-xml: Generate HMC XML Files}

\textbf{Purpose:} Generate standalone HMC XML parameter files.

Creates XML files with HMC parameters without generating SLURM scripts.

\textbf{Options:}
\begin{itemize}
\item \texttt{-e, --ensemble-id ENSEMBLE\_ID}: \textbf{Required.} Ensemble ID
\item \texttt{-m, --mode \{tepid,continue,reseed\}}: \textbf{Required.} HMC run mode
\item \texttt{-b, --base-dir BASE\_DIR}: Root directory for TUNING/ENSEMBLES
\item \texttt{-x, --xml-params XML\_PARAMS}: Space-separated XML parameters to override
\end{itemize}

\textbf{Examples:}
\begin{lstlisting}[language=bash]
$ mdwf_db hmc-xml -e 1 -m tepid -x "Trajectories=50 MDsteps=4 trajL=0.75"
Generated XML file: /scratch/lattice/ENSEMBLES/.../HMCparameters.tepid.xml

$ mdwf_db hmc-xml -e 2 -m continue -x "Trajectories=100"
Generated XML file: /scratch/lattice/ENSEMBLES/.../HMCparameters.continue.xml
\end{lstlisting}

\textbf{Generated XML Examples:}

The XML files generated show how different modes affect the HMC parameters:

\textbf{Tepid mode XML (ensemble 1):}
\begin{lstlisting}
<?xml version="1.0" ?>
<grid>
  <HMCparameters>
    <StartTrajectory>0</StartTrajectory>
    <Trajectories>100</Trajectories>
    <MetropolisTest>false</MetropolisTest>
    <StartingType>TepidStart</StartingType>      <!-- Tepid mode -->
    <Seed>776304</Seed>
    <MD>
      <name>
        <elem>OMF2_5StepV</elem>
        <elem>OMF2_5StepV</elem>
        <elem>OMF4_11StepV</elem>
      </name>
      <lvl_sizes>
        <elem>9</elem>
        <elem>1</elem>
        <elem>1</elem>
      </lvl_sizes>
    </MD>
    <MDsteps>1</MDsteps>
    <trajL>0.75</trajL>
  </HMCparameters>
</grid>
\end{lstlisting}

\textbf{Continue mode XML (ensemble 2):}
\begin{lstlisting}
<?xml version="1.0" ?>
<grid>
  <HMCparameters>
    <StartTrajectory>12</StartTrajectory>        <!-- Auto-detected start -->
    <Trajectories>50</Trajectories>
    <MetropolisTest>true</MetropolisTest>        <!-- Different from tepid -->
    <StartingType>CheckpointStart</StartingType> <!-- Continue mode -->
    <Seed>368640</Seed>                         <!-- Different seed -->
    <MD>
      <name>
        <elem>OMF2_5StepV</elem>
        <elem>OMF2_5StepV</elem>
        <elem>OMF4_11StepV</elem>
      </name>
      <lvl_sizes>
        <elem>9</elem>
        <elem>1</elem>
        <elem>1</elem>
      </lvl_sizes>
    </MD>
    <MDsteps>1</MDsteps>
    <trajL>0.75</trajL>
  </HMCparameters>
</grid>
\end{lstlisting}

\subsection{smear-script: Generate Smearing Scripts}

\textbf{Purpose:} Generate complete SLURM script for configuration smearing using GLU.

Creates GLU input files and SLURM batch scripts for GPU smearing execution.

\textbf{Options:}
\begin{itemize}
\item \texttt{-e, --ensemble-id ENSEMBLE\_ID}: \textbf{Required.} Ensemble ID
\item \texttt{-j, --job-params JOB\_PARAMS}: Space-separated SLURM job parameters
\item \texttt{-g, --glu-params GLU\_PARAMS}: Space-separated GLU parameters
\item \texttt{-o, --output-file OUTPUT\_FILE}: Custom output script path
\item \texttt{--use-default-params}: Load from ensemble default parameter file
\item \texttt{--params-variant VARIANT}: Use specific parameter variant
\item \texttt{--save-default-params}: Save current parameters to default file  
\item \texttt{--save-params-as VARIANT}: Save under custom variant name
\end{itemize}

\textbf{Required Job Parameters:}
mail\_user, config\_start, config\_end

\textbf{Common GLU Parameters:}
SMEARTYPE, SMITERS, ALPHA1, ALPHA2, ALPHA3

\textbf{Examples:}
\begin{lstlisting}[language=bash]
# Basic smearing job with custom GLU parameters
$ mdwf_db smear-script -e 1 \
    -j "mail_user=user@nersc.gov config_start=10 config_end=30 time_limit=3:00:00" \
    -g "SMITERS=8 ALPHA1=0.1"
Generated GLU input file: /private/tmp/.../cnfg_STOUT8/glu_smear.in
Wrote smearing SBATCH script to /private/tmp/.../slurm/glu_smear_STOUT8_10_30.sh

# Large-scale smearing with APE algorithm and multiple nodes
$ mdwf_db smear-script -e 3 \
    -j "mail_user=admin@lab.edu config_start=100 config_end=200 nodes=2 time_limit=8:00:00" \
    -g "SMEARTYPE=APE SMITERS=12 ALPHA1=0.05"
Generated GLU input file: /private/tmp/.../cnfg_STOUT8/glu_smear.in
Wrote smearing SBATCH script to /private/tmp/.../slurm/glu_smear_STOUT8_100_200.sh

# Use default parameters with selective overrides
$ mdwf_db smear-script -e 1 --use-default-params \
    --params-variant stout8 -j "time_limit=4:00:00"
Loaded smearing.stout8 default parameters from .../mdwf_default_params.yaml
Generated GLU input: /scratch/lattice/.../cnfg_STOUT8/glu_smear.in
Generated script: /scratch/lattice/.../slurm/glu_smear_STOUT8_100_200.sh
\end{lstlisting}

\subsection{glu-input: Generate GLU Input Files}

\textbf{Purpose:} Generate GLU input files for gauge field utility operations.

Creates properly formatted GLU input files with ensemble parameters and custom settings.

\textbf{Options:}
\begin{itemize}
\item \texttt{-e, --ensemble-id ENSEMBLE\_ID}: \textbf{Required.} Ensemble ID
\item \texttt{-o, --output-file OUTPUT\_FILE}: \textbf{Required.} Output file path
\item \texttt{-g, --glu-params GLU\_PARAMS}: Space-separated GLU parameters
\item \texttt{-t, --type \{smearing,gluon\_props,other\}}: Calculation type (default: smearing)
\end{itemize}

\textbf{Common Parameters:}
CONFNO, SMEARTYPE, SMITERS, ALPHA1, GFTYPE, ACCURACY

\textbf{Examples:}
\begin{lstlisting}[language=bash]
# Basic GLU input for smearing (default type)
$ mdwf_db glu-input -e 1 -o smear_config.in -g "CONFNO=168 SMITERS=50 ALPHA1=0.1"
Generated GLU input file: smear_config.in

# GLU input for gluon propagator calculations
$ mdwf_db glu-input -e 1 -o /tmp/custom_glu.in \
    -g "CONFNO=25 SMITERS=15 ALPHA1=0.05" -t gluon_props
Generated GLU input file: /tmp/custom_glu.in

# GLU input with gauge fixing parameters
$ mdwf_db glu-input -e 2 -o gauge_fix.in -t other \
    -g "CONFNO=100 GFTYPE=LANDAU ACCURACY=16"
Generated GLU input file: gauge_fix.in
\end{lstlisting}

\textbf{Generated GLU Input File Example:}

Here's an example of the GLU input file content generated for a 24$^3$\texttimes 48 ensemble:

\begin{lstlisting}
# Generated by: mdwf_db glu-input -e 1 -o test_glu.in -g "APE_alpha=0.6 APE_iter=50"

MODE = SMEARING    
HEADER = NERSC
    DIM_0 = 24        # Automatically set from ensemble L parameter
    DIM_1 = 24
    DIM_2 = 24
    DIM_3 = 48        # Automatically set from ensemble T parameter
CONFNO = 24
RANDOM_TRANSFORM = NO
SEED = 0
GFTYPE = COULOMB      # Default gauge fixing
    GF_TUNE = 0.09
    ACCURACY = 14
    MAX_ITERS = 650
CUTTYPE = GLUON_PROPS
FIELD_DEFINITION = LINEAR
    MOM_CUT = CYLINDER_CUT
    MAX_T = 7
    MAXMOM = 4
    CYL_WIDTH = 2.0
    ANGLE = 60
    OUTPUT = ./
SMEARTYPE = STOUT     # Default smearing type
    DIRECTION = ALL
    SMITERS = 8       # Default iterations
    ALPHA1 = 0.75     # Default alpha values
    ALPHA2 = 0.4
    ALPHA3 = 0.2
U1_MEAS = U1_RECTANGLE
    U1_ALPHA = 0.0796
    U1_CHARGE = -1.0
CONFIG_INFO = 2+1DWF_b2.25_TEST
    STORAGE = CERN
BETA = 6.0            # Derived from ensemble physics parameters
    ITERS = 1500
    MEASURE = 1
    OVER_ITERS = 4
    SAVE = 25
    THERM = 100
\end{lstlisting}

\subsection{meson2pt-script: Generate Meson Correlator Scripts}

\textbf{Purpose:} Generate WIT meson correlator measurement SLURM scripts.

Creates WIT input files and SLURM scripts for meson correlator calculations.

\textbf{Options:}
\begin{itemize}
\item \texttt{-e, --ensemble ENSEMBLE}: \textbf{Required.} Ensemble ID, directory path, or "." for current directory
\item \texttt{-j, --job-params JOB\_PARAMS}: \textbf{Required.} Space-separated key=val for SLURM job parameters
\item \texttt{-w, --wit-params WIT\_PARAMS}: Space-separated key=val for WIT parameters (dot notation)
\item \texttt{-o, --output-file OUTPUT\_FILE}: Output SBATCH script path (auto-generated if not specified)
\item \texttt{--use-default-params}: Load parameters from ensemble default parameter file
\item \texttt{--params-variant PARAMS\_VARIANT}: Specify which parameter variant to use
\item \texttt{--save-default-params}: Save current command parameters to default parameter file
\item \texttt{--save-params-as SAVE\_PARAMS\_AS}: Save current parameters under specific variant name
\end{itemize}

\textbf{Required Job Parameters:}
\begin{itemize}
\item \texttt{mail\_user}: Email address for job notifications
\item \texttt{config\_start}: First configuration number to measure
\item \texttt{config\_end}: Last configuration number to measure
\item \texttt{config\_inc}: Step/increment between configurations
\end{itemize}

\textbf{Required WIT Parameters:}
\begin{itemize}
\item \texttt{Configurations.first}: First configuration number
\item \texttt{Configurations.last}: Last configuration number
\item \texttt{Configurations.step}: Step between configurations
\end{itemize}

\textbf{Common WIT Parameters:}
\begin{itemize}
\item \texttt{Witness.no\_prop}: Number of witness propagators
\item \texttt{Solver 0.nmx}: Maximum solver iterations
\item \texttt{Propagator 0.Source}: Source type for propagators
\end{itemize}

\textbf{Examples:}
\begin{lstlisting}[language=bash]
# Basic meson measurement with debug queue
$ mdwf_db meson2pt-script -e 1 \
    -j "mail_user=test@example.com config_start=10 config_end=20 config_inc=2" \
    -w "Configurations.first=10 Configurations.last=20 Configurations.step=2"

# Use stored default parameters
$ mdwf_db meson2pt-script -e 1 --use-default-params

# Save current parameters for later reuse
$ mdwf_db meson2pt-script -e 1 \
    -j "mail_user=user@nersc.gov config_start=100 config_end=200 config_inc=4" \
    --save-default-params

Generated WIT SBATCH script: \texttt{/private/tmp/.../meson2pt/meson2pt\_10\_20.sh}
Wrote WIT SBATCH script to \texttt{/private/tmp/.../meson2pt/meson2pt\_10\_20.sh}

# Large-scale measurement with wall sources
$ mdwf_db meson-2pt -e 3 \
    -j "queue=regular time_limit=10:00:00 nodes=4 cpus_per_task=16 mail_user=hpc@university.edu" \
    -w "Configurations.first=100 Configurations.last=300 Propagator 0.Source=Wall"
WARNING: WIT parameter '0.Source' was provided but is not used in DWF.in
Generated WIT input file: /private/tmp/.../meson2pt/DWF.in
Generated WIT SBATCH script: /private/tmp/.../meson2pt/meson2pt_100_300.sh
Wrote WIT SBATCH script to /private/tmp/.../meson2pt/meson2pt_100_300.sh

# Use default parameters with custom configuration range
$ mdwf_db meson-2pt -e 1 --use-default-params \
    -w "Configurations.first=200 Configurations.last=250" -j "nodes=2"
Loaded meson_2pt.default default parameters from .../mdwf_default_params.yaml
Generated WIT input: /scratch/lattice/.../meson2pt/DWF.in
Generated script: /scratch/lattice/.../meson2pt/meson2pt_200_250.sh
\end{lstlisting}

\subsection{wit-input: Generate WIT Input Files}

\textbf{Purpose:} Generate WIT input files for meson correlator measurements.

Creates properly formatted WIT input files with ensemble parameters.

\textbf{Options:}
\begin{itemize}
\item \texttt{-e, --ensemble-id ENSEMBLE\_ID}: \textbf{Required.} Ensemble ID
\item \texttt{-o, --output-file OUTPUT\_FILE}: \textbf{Required.} Output file path
\item \texttt{-w, --wit-params WIT\_PARAMS}: Space-separated WIT parameters (dot notation)
\end{itemize}

\textbf{Common Parameters:}
Configurations.first, Configurations.last, Configurations.step, Propagator 0.Source

\textbf{Example:}
\begin{lstlisting}[language=bash]
$ mdwf_db wit-input -e 1 -o DWF.in \
    -w "Configurations.first=100 Configurations.last=200 Configurations.step=2"
Generated WIT input file: DWF.in
\end{lstlisting}

\subsection{update: Track Operation Status}

\textbf{Purpose:} Create or update operation records in the database.

Records operation status, parameters, and execution details for tracking job progress.

\textbf{Options:}
\begin{itemize}
\item \texttt{-e, --ensemble-id ENSEMBLE\_ID}: \textbf{Required.} Ensemble ID
\item \texttt{-o, --operation-type OPERATION\_TYPE}: \textbf{Required.} Operation type
\item \texttt{-s, --status \{RUNNING,COMPLETED,FAILED\}}: \textbf{Required.} Operation status
\item \texttt{-i, --operation-id OPERATION\_ID}: Existing operation ID to update
\item \texttt{-p, --params PARAMS}: Space-separated key=val operation details
\end{itemize}

\textbf{Common Operation Types:}
HMC\_TUNE, HMC\_PRODUCTION, GLU\_SMEAR, WIT\_MESON2PT, PROMOTE\_ENSEMBLE

\textbf{Common Parameters:}
config\_start, config\_end, exit\_code, runtime, slurm\_job, host

\textbf{Examples:}
\begin{lstlisting}[language=bash]
# Record new running HMC operation
$ mdwf_db update -e 1 -o HMC_TUNE -s RUNNING \
    -p "config_start=0 config_end=50 slurm_job=123456"
Created operation 1: Created

# Record completed smearing operation with timing info
$ mdwf_db update -e 2 -o GLU_SMEAR -s COMPLETED \
    -p "config_start=10 config_end=30 exit_code=0 runtime=1800"
Created operation 2: Created

# Record failed meson measurement with error details
$ mdwf_db update -e 3 -o WIT_MESON2PT -s FAILED \
    -p "config_start=100 config_end=150 exit_code=1 error_msg=Out_of_memory"
Created operation 3: Created

# Update existing operation status to completed
$ mdwf_db update -e 1 -o HMC_TUNE -s COMPLETED -i 1 \
    -p "exit_code=0 runtime=14400 final_config=50"
Updated operation 1: Updated

# Record operation with hostname and user info
$ mdwf_db update -e 2 -o PROMOTE_ENSEMBLE -s COMPLETED \
    -p "host=perlmutter-node01 runtime=5"
Created operation 4: Created
\end{lstlisting}

\subsection{clear-history: Clear Operation History}

\textbf{Purpose:} Clear all operation history for an ensemble while preserving the ensemble record.

Removes all operation records but keeps ensemble metadata and physics parameters.

\textbf{Options:}
\begin{itemize}
\item \texttt{-e, --ensemble ENSEMBLE}: \textbf{Required.} Ensemble to clear (ID, path, or ".")
\item \texttt{--force}: Skip confirmation prompt
\end{itemize}

\textbf{What is Removed:}
All operation records, parameters, timestamps, and status information

\textbf{What is Preserved:}
Ensemble record, physics parameters, description, creation time

\textbf{Examples:}
\begin{lstlisting}[language=bash]
# Clear history with confirmation prompt
$ mdwf_db clear-history -e 1
Clear all operation history for ensemble 1? This cannot be undone. (y/N) y
Cleared 2 operations for ensemble 1

# Clear history with --force flag (no prompt)
$ mdwf_db clear-history -e 3 --force
Ensemble 3: /private/tmp/.../ENSEMBLES/b6.2/b1.5Ls32/mc0.8/ms0.06/ml0.015/L48/T96
Found 1 operation(s) to clear
Successfully cleared 1 operation(s) from ensemble 3

# Verify history is cleared (query shows no operations)
$ mdwf_db query -e 3
ID          = 3
Directory   = /private/tmp/.../ENSEMBLES/b6.2/b1.5Ls32/mc0.8/ms0.06/ml0.015/L48/T96
Status      = PRODUCTION
Created     = 2025-08-06T12:40:50.104567
Description = Large production ensemble - 48^3x96
Parameters:
    L = 48
    ...

=== Operation history ===
No operations recorded
\end{lstlisting}

\subsection{remove-ensemble: Remove Ensemble}

\textbf{Purpose:} Remove ensemble and all its operations from the database.

Completely removes ensemble record and all associated operations. Directory structure is not deleted.

\textbf{Options:}
\begin{itemize}
\item \texttt{-e, --ensemble ENSEMBLE}: \textbf{Required.} Ensemble to remove (ID, path, or ".")
\item \texttt{--force}: Skip confirmation prompt
\end{itemize}

\textbf{Example:}
\begin{lstlisting}[language=bash]
$ mdwf_db remove-ensemble -e 1
Remove ensemble 1 and all its operations? This cannot be undone. (y/N) y
Removed ensemble 1 and 3 operations
\end{lstlisting}

\subsection{mres-script: Generate MRES Measurement Scripts}

\textbf{Purpose:} Generate WIT MRES measurement SLURM scripts for mass renormalization.

\textbf{Options:}
\begin{itemize}
\item \texttt{-e, --ensemble ENSEMBLE}: \textbf{Required.} Ensemble ID, directory path, or "." for current directory
\item \texttt{-j, --job-params JOB\_PARAMS}: \textbf{Required.} Space-separated key=val for SLURM job parameters
\item \texttt{-g, --glu-params GLU\_PARAMS}: Space-separated key=val for GLU parameters
\item \texttt{-o, --output-file OUTPUT\_FILE}: Output SBATCH script path (auto-generated if not specified)
\item \texttt{--use-default-params}: Load parameters from ensemble default parameter file
\item \texttt{--params-variant PARAMS\_VARIANT}: Specify which parameter variant to use
\item \texttt{--save-default-params}: Save current command parameters to default parameter file
\item \texttt{--save-params-as SAVE\_PARAMS\_AS}: Save current parameters under specific variant name
\end{itemize}

\textbf{Required Job Parameters:}
\begin{itemize}
\item \texttt{mail\_user}: Email address for job notifications
\item \texttt{config\_start}: First configuration number to measure
\item \texttt{config\_end}: Last configuration number to measure
\item \texttt{config\_inc}: Step/increment between configurations
\end{itemize}

\textbf{Examples:}
\begin{lstlisting}[language=bash]
# Basic MRES measurement job
mdwf_db mres-script -e 1 \
  -j "mail_user=user@example.com config_start=100 config_end=200 config_inc=4"

# Use stored default parameters
mdwf_db mres-script -e 1 --use-default-params

# Save current parameters for later reuse
mdwf_db mres-script -e 1 \
  -j "mail_user=user@nersc.gov config_start=100 config_end=200 config_inc=4" \
  --save-default-params
\end{lstlisting}

\subsection{wflow-script: Generate Gradient Flow Scripts}

\textbf{Purpose:} Generate gradient flow SLURM scripts for Wilson flow measurements.

\textbf{Options:}
\begin{itemize}
\item \texttt{-e, --ensemble ENSEMBLE}: \textbf{Required.} Ensemble ID, directory path, or "." for current directory
\item \texttt{-j, --job-params JOB\_PARAMS}: \textbf{Required.} Space-separated key=val for SLURM job parameters
\item \texttt{-g, --glu-params GLU\_PARAMS}: Space-separated key=val for GLU parameters
\item \texttt{-o, --output-file OUTPUT\_FILE}: Output SBATCH script path (auto-generated if not specified)
\item \texttt{--use-default-params}: Load parameters from ensemble default parameter file
\item \texttt{--params-variant PARAMS\_VARIANT}: Specify which parameter variant to use
\item \texttt{--save-default-params}: Save current command parameters to default parameter file
\item \texttt{--save-params-as SAVE\_PARAMS\_AS}: Save current parameters under specific variant name
\end{itemize}

\textbf{Required Job Parameters:}
\begin{itemize}
\item \texttt{mail\_user}: Email address for job notifications
\item \texttt{config\_start}: First configuration number to measure
\item \texttt{config\_end}: Last configuration number to measure
\item \texttt{config\_inc}: Step/increment between configurations
\end{itemize}

\textbf{Examples:}
\begin{lstlisting}[language=bash]
# Basic gradient flow job
mdwf_db wflow-script -e 1 \
  -j "mail_user=user@example.com config_start=100 config_end=200 config_inc=4"

# Use stored default parameters
mdwf_db wflow-script -e 1 --use-default-params

# Save current parameters for later reuse
mdwf_db wflow-script -e 1 \
  -j "mail_user=user@nersc.gov config_start=100 config_end=200 config_inc=4" \
  --save-default-params
\end{lstlisting}

\subsection{default\_params: Parameter Management}

\textbf{Purpose:} Manage default parameter files for storing operation parameters.

Save "recipes" of parameters that work well for specific ensembles and reuse them in script generation commands.

\textbf{Subcommands:}
\begin{itemize}
\item \texttt{generate}: Generate a template default parameter file
\item \texttt{show}: Display current default parameters  
\item \texttt{edit}: Edit default parameter file
\item \texttt{validate}: Validate default parameter file
\end{itemize}

\textbf{Options:}
\begin{itemize}
\item \texttt{-e, --ensemble ENSEMBLE}: \textbf{Required.} Ensemble to manage (ID, path, or ".")
\item \texttt{--format \{yaml,json\}}: File format for generation (default: yaml)
\end{itemize}

\textbf{Parameter File Structure:}
Parameters are organized by operation type and mode/variant:

\begin{lstlisting}
hmc:
  tepid:
    xml_params: "StartTrajectory=0 Trajectories=100 MDsteps=2"
    job_params: "cfg_max=100 time_limit=12:00:00 nodes=1"
  continue:
    xml_params: "Trajectories=50 MDsteps=2"
    job_params: "cfg_max=500 time_limit=6:00:00"
    
smearing:
  stout8:
    params: "nsteps=8 rho=0.1"
    job_params: "time_limit=2:00:00"

meson_2pt:
  default:
    params: "source_type=point sink_type=point"
    job_params: "time_limit=4:00:00"
\end{lstlisting}

\textbf{Usage with Other Commands:}
Use \texttt{--use-default-params} flag in script commands to load parameters from the file. CLI parameters override default parameters.

\textbf{Examples:}
\begin{lstlisting}[language=bash]
# Generate complete template file with all operation types
$ mdwf_db default_params generate -e 1
Generated configuration template: /private/tmp/.../mdwf_default_params.yaml
Edit this file to customize parameters for your ensemble

# View all available parameter configurations
$ mdwf_db default_params show -e 1
Configuration file: /private/tmp/.../mdwf_default_params.yaml
Available operation configurations:

  hmc:
    tepid:
      xml_params: StartTrajectory=0 Trajectories=100 MDsteps=2 trajL=0.75 MetropolisTest=false
      job_params: cfg_max=100 time_limit=12:00:00 nodes=1 constraint=gpu cpus_per_task=32
    continue:
      xml_params: Trajectories=50 MDsteps=2 trajL=0.75 MetropolisTest=true
      job_params: cfg_max=500 time_limit=6:00:00 nodes=1 constraint=gpu cpus_per_task=32
    reseed:
      xml_params: StartTrajectory=0 Trajectories=200 MDsteps=2 trajL=0.75 MetropolisTest=true
      job_params: cfg_max=200 time_limit=12:00:00 nodes=1 constraint=gpu cpus_per_task=32

  smearing:
    stout8:
      params: nsteps=8 rho=0.1
      job_params: time_limit=2:00:00 nodes=1
    stout4:
      params: nsteps=4 rho=0.15
      job_params: time_limit=1:30:00 nodes=1

  meson_2pt:
    default:
      params: source_type=point sink_type=point
      job_params: time_limit=4:00:00 nodes=1
    wall:
      params: source_type=wall sink_type=point
      job_params: time_limit=6:00:00 nodes=2

  wit:
    default:
      params: mass_preset=physical
      job_params: time_limit=8:00:00 nodes=2

  mres:
    default:
      params: mass_preset=physical
      job_params: time_limit=6:00:00 nodes=1

  wflow:
    default:
      params: flow_time=0.1
      job_params: time_limit=2:00:00 nodes=1

# Show updated parameters after saving new ones
$ mdwf_db default_params show -e 1
Configuration file: /private/tmp/.../mdwf_default_params.yaml
Available operation configurations:

  hmc:
    tepid:
      xml_params: MDsteps=6 trajL=0.5
      job_params: cfg_max=25 time_limit=3:00:00
    continue:
      xml_params: Trajectories=50 MDsteps=2 trajL=0.75 MetropolisTest=true
      job_params: cfg_max=500 time_limit=6:00:00 nodes=1 constraint=gpu cpus_per_task=32
    ...

# Use parameters with CLI overrides  
$ mdwf_db hmc-script -e 1 -a m2986 -m continue --use-default-params -j "nodes=2"
Loaded HMC continue default parameters from .../mdwf_default_params.yaml
$ mdwf_db smear-script -e 1 --use-default-params --params-variant stout8
Loaded smearing.stout8 default parameters from .../mdwf_default_params.yaml
\end{lstlisting}

\section{Default Parameter System}

The MDWF system includes a comprehensive default parameter management system for reproducible workflows. This system allows you to save "recipes" of parameters that work well for specific ensembles and reuse them across different operations.

\subsection{Default Parameter Files}

Default parameters are stored in \texttt{mdwf\_default\_params.yaml} files within each ensemble directory:

\begin{lstlisting}
---
hmc:
  tepid:
    xml_params: "StartTrajectory=0 Trajectories=100 MDsteps=2 trajL=0.75"
    job_params: "cfg_max=100 time_limit=12:00:00 nodes=1 constraint=gpu"
  continue:
    xml_params: "Trajectories=50 MDsteps=2 trajL=0.75"
    job_params: "cfg_max=500 time_limit=6:00:00"
    
smearing:
  stout8:
    params: "nsteps=8 rho=0.1"
    job_params: "time_limit=2:00:00"

meson_2pt:
  default:
    params: "source_type=point sink_type=point"
    job_params: "time_limit=4:00:00"
\end{lstlisting}

\subsection{Parameter Precedence}

When using default parameters, the system follows this precedence order:

\begin{enumerate}
\item \textbf{CLI parameters} (highest priority) - explicitly specified on command line
\item \textbf{Default parameters} - loaded from ensemble's \texttt{mdwf\_default\_params.yaml}
\item \textbf{Command defaults} - built-in defaults for each command
\end{enumerate}

This means you can:
\begin{itemize}
\item Use \texttt{--use-default-params} to load all parameters from the file
\item Override specific parameters with CLI options
\item Mix default and CLI parameters for flexible workflows
\end{itemize}

\subsection{CLI Parameter Handling}

The system provides several options for managing default parameters:

\begin{itemize}
\item \texttt{--use-default-params}: Load parameters from ensemble's default parameter file
\item \texttt{--save-default-params}: Save current command parameters to the default file
\item \texttt{--params-variant PARAMS\_VARIANT}: Use a specific parameter variant (e.g., "tepid", "continue")
\item \texttt{--save-params-as SAVE\_PARAMS\_AS}: Save current parameters under a custom variant name
\end{itemize}

\textbf{Examples:}

\begin{lstlisting}[language=bash]
# Load default parameters for HMC continue mode
$ mdwf_db hmc-script -e 1 -a m2986 -m continue --use-default-params

# Save current parameters as new variant
$ mdwf_db hmc-script -e 1 -a m2986 -m continue \
    -x "Trajectories=200 MDsteps=4" \
    -j "time_limit=24:00:00" \
    --save-params-as long_run

# Use new variant
mdwf_db smear-script -e 1 --use-default-params --params-variant stout12
\end{lstlisting}

\end{document}
